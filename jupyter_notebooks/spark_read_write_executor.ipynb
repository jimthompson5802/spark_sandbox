{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4006e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import functools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf953eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/jovyan/data\"\n",
    "RESULTS_DIR = \"/home/jovyan/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 102)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from the relative path\n",
    "df = pd.read_csv(os.path.join(DATA_DIR,\"synthetic_regression_data.csv\"))\n",
    "\n",
    "# Display the first few rows to verify the data was loaded correctly\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0-preview2\n",
      "Spark UI available at: http://309ff094cbf4:4040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkDataScienceSample\") \\\n",
    "    .master(os.environ.get(\"SPARK_MASTER\", \"spark://spark-master:7077\")) \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278def58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark DataFrame from the Pandas DataFrame\n",
    "spark_df = spark.createDataFrame(df).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e89703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few rows of the Spark DataFrame\n",
    "# spark_df.show(5)\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5c8b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe55139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique fold ids from the spark DataFrame\n",
    "fold_ids = sorted(spark_df.select(\"fold_id\").distinct().rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857d521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_set(fold_id):\n",
    "    \"\"\"\n",
    "    Reads the synthetic regression dataset, splits it into training and testing sets based on the given fold ID, \n",
    "    and saves the metadata (fold ID, type, and shape) as a CSV file in the results directory.\n",
    "\n",
    "    Args:\n",
    "        fold_id (int): The fold ID to use for splitting the dataset into training and testing sets.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path of the saved CSV file containing the metadata.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(os.path.join(DATA_DIR, \"synthetic_regression_data.parquet\"))\n",
    "\n",
    "    train_df = df[df[\"fold_id\"] != fold_id]\n",
    "    test_df = df[df[\"fold_id\"] == fold_id]\n",
    "\n",
    "    fp = os.path.join(RESULTS_DIR, \"synthetic_regression_data_fold_{}.csv\".format(fold_id))\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            {\"fold_id\": fold_id, \"type\": \"train\", \"shape\": train_df.shape},\n",
    "            {\"fold_id\": fold_id, \"type\": \"test\", \"shape\": test_df.shape},\n",
    "        ]\n",
    "    ).to_csv(fp, index=False)\n",
    "    \n",
    "    return fp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c624c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: ['/home/jovyan/results/synthetic_regression_data_fold_0.csv', '/home/jovyan/results/synthetic_regression_data_fold_1.csv', '/home/jovyan/results/synthetic_regression_data_fold_2.csv', '/home/jovyan/results/synthetic_regression_data_fold_3.csv']\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD (Resilient Distributed Dataset) from the list of fold IDs\n",
    "# The RDD is partitioned into 4 slices for parallel processing\n",
    "rdd = sc.parallelize(fold_ids, numSlices=4)\n",
    "\n",
    "# Use the RDD to map each fold ID to the result of the `read_data_set` function\n",
    "# The `read_data_set` function processes the data for each fold and returns the file path of the saved metadata\n",
    "results = rdd.map(lambda x: read_data_set(x)).collect()\n",
    "\n",
    "# Print the list of results (file paths of the saved metadata for each fold)\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbc8f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: synthetic_regression_data_fold_1.csv\n",
      "   fold_id   type         shape\n",
      "0        1  train  (75000, 102)\n",
      "1        1   test  (25000, 102)\n",
      "\n",
      "\n",
      "File: synthetic_regression_data_fold_0.csv\n",
      "   fold_id   type         shape\n",
      "0        0  train  (75000, 102)\n",
      "1        0   test  (25000, 102)\n",
      "\n",
      "\n",
      "File: synthetic_regression_data_fold_2.csv\n",
      "   fold_id   type         shape\n",
      "0        2  train  (75000, 102)\n",
      "1        2   test  (25000, 102)\n",
      "\n",
      "\n",
      "File: synthetic_regression_data_fold_3.csv\n",
      "   fold_id   type         shape\n",
      "0        3  train  (75000, 102)\n",
      "1        3   test  (25000, 102)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all files in the RESULTS_DIR directory\n",
    "for f in os.listdir(RESULTS_DIR):\n",
    "    # Check if the file has a .csv extension\n",
    "    if f.endswith(\".csv\"):\n",
    "        # Print the file name and contents\n",
    "        print(f\"File: {f}\")\n",
    "        df = pd.read_csv(os.path.join(RESULTS_DIR, f))\n",
    "        print(df)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3afb8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130eca36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
