{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4006e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf953eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/jovyan/data\"\n",
    "RESULTS_DIR = \"/home/jovyan/results/classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1710215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the results directory\n",
    "if os.path.exists(RESULTS_DIR):\n",
    "    for item in os.listdir(RESULTS_DIR):\n",
    "        item_path = os.path.join(RESULTS_DIR, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            import shutil\n",
    "            shutil.rmtree(item_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd8502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0-preview2\n",
      "Spark UI available at: http://2309e119b7ae:4040\n"
     ]
    }
   ],
   "source": [
    "# .config((\"spark.driver.maxResultSize\", \"4g\")) \\\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkLightgbmClassification\") \\\n",
    "    .master(os.environ.get(\"SPARK_MASTER\", \"spark://spark-master:7077\")) \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\") \\\n",
    "    .config(\"spark.python.worker.faulthandler.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a521bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique fold ids from the spark DataFrame\n",
    "fold_ids = [1, 2, 3, 4]\n",
    "\n",
    "fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857d521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm_model(params=None):\n",
    "    \"\"\"\n",
    "    Train a LightGBM classification model with the specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    params : dict, optional\n",
    "        Parameters for LGBMClassifier. If None, default parameters will be used.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        File path where results are stored\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Training LightGBM classification model...{params}\")\n",
    "    # Default parameters if none provided\n",
    "    if params is None:\n",
    "        raise ValueError(\"No parameters provided for LightGBM model.\")\n",
    "    \n",
    "    fold_id = params.pop(\"fold_id\")\n",
    "\n",
    "    test_df = pd.read_parquet(\n",
    "        os.path.join(DATA_DIR, f\"ts_fold_{fold_id}_test.parquet\"),\n",
    "    )\n",
    "    train_df = pd.read_parquet(\n",
    "        os.path.join(DATA_DIR, f\"ts_fold_{fold_id}_train.parquet\"),\n",
    "    )\n",
    "\n",
    "    train_x = train_df.drop(columns=[\"target\", \"date\"])\n",
    "    train_y = train_df[\"target\"]\n",
    "    test_x = test_df.drop(columns=[\"target\", \"date\"])\n",
    "    test_y = test_df[\"target\"]\n",
    "\n",
    "    # Initialize the classification model\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    # Train the model and measure time\n",
    "    start_time = time.perf_counter()\n",
    "    model.fit(\n",
    "        train_x, train_y,\n",
    "        eval_set=[(test_x, test_y)],\n",
    "        eval_metric='logloss',\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=2000),\n",
    "            lgb.log_evaluation(period=100),\n",
    "        ]\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(test_x)[:, 1]  # Probability of positive class\n",
    "    y_pred = model.predict(test_x)  # Class predictions\n",
    "    \n",
    "    # Calculate classification metrics\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    precision = precision_score(test_y, y_pred)\n",
    "    recall = recall_score(test_y, y_pred)\n",
    "    f1 = f1_score(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred_proba)\n",
    "\n",
    "    # Store detailed classification report as string\n",
    "    class_report = classification_report(test_y, y_pred)\n",
    "    print(f\"\\nClassification Report for fold {fold_id}:\")\n",
    "    print(class_report)\n",
    "\n",
    "    results = {\n",
    "        \"fold_id\": fold_id,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "    results.update(params)\n",
    "\n",
    "    # generate uuid string for the results file name\n",
    "    fp_id = str(uuid.uuid4())\n",
    "    fp_name = os.path.join(RESULTS_DIR, f\"results_fold_{fold_id}_{fp_id}.parquet\")\n",
    "\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_df.to_parquet(\n",
    "        fp_name,\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    return fp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f0fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameter combinations: 216\n",
      "\n",
      "First 3 parameter combinations:\n",
      "Combination 1:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.1, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.01, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n",
      "Combination 2:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.1, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.1, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n",
      "Combination 3:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.3, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.01, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    \"n_jobs\": [2],\n",
    "    \"fold_id\": fold_ids,\n",
    "    \"lambda_l1\": [0.3, 12, 40],\n",
    "    \"max_depth\": [10, 15, 17],\n",
    "    \"colsample_bytree\": [0.1, 0.3, 0.4],\n",
    "    \"alpha\": [0.2],\n",
    "    \"num_leaves\": [2048,],\n",
    "    \"learning_rate\": [0.03],\n",
    "    \"lambda_l2\": [0.01, 0.1],\n",
    "    \"max_bin\": [256,],\n",
    "    \"bagging_fraction\": [1],\n",
    "    \"deterministic\": [False],\n",
    "    \"objective\": [\"huber\"],\n",
    "    \"metric\": [\"huber\"],\n",
    "    \"n_estimators\": [20000],\n",
    "    \"random_state\": [42],\n",
    "    \"importance_type\": [\"gain\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_keys = list(param_grid.keys())\n",
    "param_values = list(param_grid.values())\n",
    "param_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "# Create a list of dictionaries, each representing a specific combination\n",
    "param_dicts = []\n",
    "for combo in param_combinations:\n",
    "    param_dict = dict(zip(param_keys, combo))\n",
    "    param_dicts.append(param_dict)\n",
    "\n",
    "# Display the number of combinations and the first few combinations\n",
    "print(f\"Total number of parameter combinations: {len(param_dicts)}\")\n",
    "print(\"\\nFirst 3 parameter combinations:\")\n",
    "for i in range(min(3, len(param_dicts))):\n",
    "    print(f\"Combination {i+1}:\")\n",
    "    print(param_dicts[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c624c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>length of rdd_result: 216\n"
     ]
    }
   ],
   "source": [
    "process_these = param_dicts\n",
    "\n",
    "rdd = sc.parallelize(process_these, numSlices=len(process_these))\n",
    "\n",
    "rdd_result = rdd.map(lambda x: train_lightgbm_model(params=x)).collect()\n",
    "\n",
    "print(f\">>>>length of rdd_result: {len(rdd_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248fd044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      fold_id  accuracy  precision    recall  f1_score   auc_roc  \\\n",
       "0          1   0.81640   0.965170  0.567481  0.714730  0.956283   \n",
       "1          1   0.81325   0.967487  0.557982  0.707769  0.956144   \n",
       "2          1   0.88485   0.969574  0.739082  0.838782  0.967396   \n",
       "3          1   0.88735   0.969819  0.745250  0.842832  0.966985   \n",
       "4          1   0.88930   0.966434  0.753022  0.846485  0.966572   \n",
       "..       ...       ...        ...       ...       ...       ...   \n",
       "211        4   0.77995   0.971112  0.467470  0.631129  0.961920   \n",
       "212        4   0.76705   0.972710  0.433698  0.599914  0.963520   \n",
       "213        4   0.76840   0.972913  0.437050  0.603153  0.963821   \n",
       "214        4   0.78215   0.974339  0.471443  0.635428  0.963353   \n",
       "215        4   0.77905   0.974419  0.463496  0.628187  0.962717   \n",
       "\n",
       "     training_time  n_jobs  lambda_l1  max_depth  ...  learning_rate  \\\n",
       "0        19.079455       2        0.3         10  ...           0.03   \n",
       "1        16.911805       2        0.3         10  ...           0.03   \n",
       "2        27.607863       2        0.3         10  ...           0.03   \n",
       "3        27.105119       2        0.3         10  ...           0.03   \n",
       "4        29.998220       2        0.3         10  ...           0.03   \n",
       "..             ...     ...        ...        ...  ...            ...   \n",
       "211      17.740628       2       40.0         17  ...           0.03   \n",
       "212      19.005219       2       40.0         17  ...           0.03   \n",
       "213      18.461342       2       40.0         17  ...           0.03   \n",
       "214      21.505736       2       40.0         17  ...           0.03   \n",
       "215      19.895725       2       40.0         17  ...           0.03   \n",
       "\n",
       "     lambda_l2  max_bin  bagging_fraction  deterministic  objective  metric  \\\n",
       "0         0.01      256                 1          False      huber   huber   \n",
       "1         0.10      256                 1          False      huber   huber   \n",
       "2         0.01      256                 1          False      huber   huber   \n",
       "3         0.10      256                 1          False      huber   huber   \n",
       "4         0.01      256                 1          False      huber   huber   \n",
       "..         ...      ...               ...            ...        ...     ...   \n",
       "211       0.10      256                 1          False      huber   huber   \n",
       "212       0.01      256                 1          False      huber   huber   \n",
       "213       0.10      256                 1          False      huber   huber   \n",
       "214       0.01      256                 1          False      huber   huber   \n",
       "215       0.10      256                 1          False      huber   huber   \n",
       "\n",
       "     n_estimators random_state importance_type  \n",
       "0           20000           42            gain  \n",
       "1           20000           42            gain  \n",
       "2           20000           42            gain  \n",
       "3           20000           42            gain  \n",
       "4           20000           42            gain  \n",
       "..            ...          ...             ...  \n",
       "211         20000           42            gain  \n",
       "212         20000           42            gain  \n",
       "213         20000           42            gain  \n",
       "214         20000           42            gain  \n",
       "215         20000           42            gain  \n",
       "\n",
       "[216 rows x 23 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [pd.read_parquet(fp) for fp in rdd_result]\n",
    "results_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "results_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c97346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "training_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "auc_roc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1e32b482-8f11-4cca-8bb5-b50887c6b589",
       "rows": [
        [
         "count",
         "216.0",
         "216.0",
         "216.0",
         "216.0",
         "216.0",
         "216.0"
        ],
        [
         "mean",
         "34.26999430087027",
         "0.8232305555555555",
         "0.9700748345758062",
         "0.5819452119264766",
         "0.7111745114300854",
         "0.9640105873393752"
        ],
        [
         "std",
         "29.279173387549957",
         "0.06944329318942362",
         "0.003744583489593839",
         "0.1780947845944302",
         "0.14130544379048182",
         "0.0056740065316803565"
        ],
        [
         "min",
         "3.6307241679987783",
         "0.6869",
         "0.9579591836734694",
         "0.23451764125339256",
         "0.3777821939586645",
         "0.9492086234557076"
        ],
        [
         "25%",
         "12.99136561000023",
         "0.7703625",
         "0.9678946923747354",
         "0.44628046860596965",
         "0.6120053100355337",
         "0.9615912590121007"
        ],
        [
         "50%",
         "25.3979318039992",
         "0.81515",
         "0.9708820558086092",
         "0.5623218931978688",
         "0.7123123810516166",
         "0.9651170824228212"
        ],
        [
         "75%",
         "46.39564282275023",
         "0.8785875",
         "0.972742666769628",
         "0.7215451650654897",
         "0.8280891677238562",
         "0.9683104540006504"
        ],
        [
         "max",
         "133.22950739299995",
         "0.94015",
         "0.9758924432081595",
         "0.8867550489406517",
         "0.9227694687983496",
         "0.971966813642013"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.269994</td>\n",
       "      <td>0.823231</td>\n",
       "      <td>0.970075</td>\n",
       "      <td>0.581945</td>\n",
       "      <td>0.711175</td>\n",
       "      <td>0.964011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.279173</td>\n",
       "      <td>0.069443</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.178095</td>\n",
       "      <td>0.141305</td>\n",
       "      <td>0.005674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.630724</td>\n",
       "      <td>0.686900</td>\n",
       "      <td>0.957959</td>\n",
       "      <td>0.234518</td>\n",
       "      <td>0.377782</td>\n",
       "      <td>0.949209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.991366</td>\n",
       "      <td>0.770362</td>\n",
       "      <td>0.967895</td>\n",
       "      <td>0.446280</td>\n",
       "      <td>0.612005</td>\n",
       "      <td>0.961591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.397932</td>\n",
       "      <td>0.815150</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.562322</td>\n",
       "      <td>0.712312</td>\n",
       "      <td>0.965117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.395643</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.972743</td>\n",
       "      <td>0.721545</td>\n",
       "      <td>0.828089</td>\n",
       "      <td>0.968310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.229507</td>\n",
       "      <td>0.940150</td>\n",
       "      <td>0.975892</td>\n",
       "      <td>0.886755</td>\n",
       "      <td>0.922769</td>\n",
       "      <td>0.971967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       training_time    accuracy   precision      recall    f1_score  \\\n",
       "count     216.000000  216.000000  216.000000  216.000000  216.000000   \n",
       "mean       34.269994    0.823231    0.970075    0.581945    0.711175   \n",
       "std        29.279173    0.069443    0.003745    0.178095    0.141305   \n",
       "min         3.630724    0.686900    0.957959    0.234518    0.377782   \n",
       "25%        12.991366    0.770362    0.967895    0.446280    0.612005   \n",
       "50%        25.397932    0.815150    0.970882    0.562322    0.712312   \n",
       "75%        46.395643    0.878587    0.972743    0.721545    0.828089   \n",
       "max       133.229507    0.940150    0.975892    0.886755    0.922769   \n",
       "\n",
       "          auc_roc  \n",
       "count  216.000000  \n",
       "mean     0.964011  \n",
       "std      0.005674  \n",
       "min      0.949209  \n",
       "25%      0.961591  \n",
       "50%      0.965117  \n",
       "75%      0.968310  \n",
       "max      0.971967  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[\"training_time\", \"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auc_roc\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afb8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
