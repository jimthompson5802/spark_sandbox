{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4006e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import uuid\n",
    "from spark_helper.core import create_spark_session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf953eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/jovyan/data\"\n",
    "RESULTS_DIR = \"/home/jovyan/results/classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1710215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the results directory\n",
    "if os.path.exists(RESULTS_DIR):\n",
    "    for item in os.listdir(RESULTS_DIR):\n",
    "        item_path = os.path.join(RESULTS_DIR, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            import shutil\n",
    "            shutil.rmtree(item_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd8502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0-preview2\n",
      "Spark UI available at: http://2c39b2b1ca38:4040\n"
     ]
    }
   ],
   "source": [
    "# .config((\"spark.driver.maxResultSize\", \"4g\")) \\\n",
    "# Create a Spark session\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"SparkLightgbmClassification\") \\\n",
    "#     .master(os.environ.get(\"SPARK_MASTER\", \"spark://spark-master:7077\")) \\\n",
    "#     .config(\"spark.executor.memory\", \"4g\") \\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"1g\") \\\n",
    "#     .config(\"spark.python.worker.faulthandler.enabled\", \"true\") \\\n",
    "#     .config(\"spark.sql.execution.pyspark.udf.faulthandler.enabled\", \"true\") \\\n",
    "#     .getOrCreate()\n",
    "spark = create_spark_session(\"spark_cluster.yaml\")\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a521bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique fold ids from the spark DataFrame\n",
    "fold_ids = [1, 2, 3, 4]\n",
    "\n",
    "fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857d521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm_model(params=None):\n",
    "    \"\"\"\n",
    "    Train a LightGBM classification model with the specified parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    params : dict, optional\n",
    "        Parameters for LGBMClassifier. If None, default parameters will be used.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        File path where results are stored\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Training LightGBM classification model...{params}\")\n",
    "    # Default parameters if none provided\n",
    "    if params is None:\n",
    "        raise ValueError(\"No parameters provided for LightGBM model.\")\n",
    "    \n",
    "    fold_id = params.pop(\"fold_id\")\n",
    "\n",
    "    test_df = pd.read_parquet(\n",
    "        os.path.join(DATA_DIR, f\"ts_fold_{fold_id}_test.parquet\"),\n",
    "    )\n",
    "    train_df = pd.read_parquet(\n",
    "        os.path.join(DATA_DIR, f\"ts_fold_{fold_id}_train.parquet\"),\n",
    "    )\n",
    "\n",
    "    train_x = train_df.drop(columns=[\"target\", \"date\"])\n",
    "    train_y = train_df[\"target\"]\n",
    "    test_x = test_df.drop(columns=[\"target\", \"date\"])\n",
    "    test_y = test_df[\"target\"]\n",
    "\n",
    "    # Initialize the classification model\n",
    "    model = LGBMClassifier(**params)\n",
    "    \n",
    "    # Train the model and measure time\n",
    "    start_time = time.perf_counter()\n",
    "    model.fit(\n",
    "        train_x, train_y,\n",
    "        eval_set=[(test_x, test_y)],\n",
    "        eval_metric='logloss',\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=2000),\n",
    "            lgb.log_evaluation(period=100),\n",
    "        ]\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(test_x)[:, 1]  # Probability of positive class\n",
    "    y_pred = model.predict(test_x)  # Class predictions\n",
    "    \n",
    "    # Calculate classification metrics\n",
    "    accuracy = accuracy_score(test_y, y_pred)\n",
    "    precision = precision_score(test_y, y_pred)\n",
    "    recall = recall_score(test_y, y_pred)\n",
    "    f1 = f1_score(test_y, y_pred)\n",
    "    auc = roc_auc_score(test_y, y_pred_proba)\n",
    "\n",
    "    # Store detailed classification report as string\n",
    "    class_report = classification_report(test_y, y_pred)\n",
    "    print(f\"\\nClassification Report for fold {fold_id}:\")\n",
    "    print(class_report)\n",
    "\n",
    "    results = {\n",
    "        \"fold_id\": fold_id,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc,\n",
    "        'training_time': training_time,\n",
    "    }\n",
    "    results.update(params)\n",
    "\n",
    "    # generate uuid string for the results file name\n",
    "    fp_id = str(uuid.uuid4())\n",
    "    fp_name = os.path.join(RESULTS_DIR, f\"results_fold_{fold_id}_{fp_id}.parquet\")\n",
    "\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_df.to_parquet(\n",
    "        fp_name,\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    return fp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f0fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameter combinations: 216\n",
      "\n",
      "First 3 parameter combinations:\n",
      "Combination 1:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.1, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.01, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n",
      "Combination 2:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.1, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.1, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n",
      "Combination 3:\n",
      "{'n_jobs': 2, 'fold_id': 1, 'lambda_l1': 0.3, 'max_depth': 10, 'colsample_bytree': 0.3, 'alpha': 0.2, 'num_leaves': 2048, 'learning_rate': 0.03, 'lambda_l2': 0.01, 'max_bin': 256, 'bagging_fraction': 1, 'deterministic': False, 'objective': 'huber', 'metric': 'huber', 'n_estimators': 20000, 'random_state': 42, 'importance_type': 'gain'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    \"n_jobs\": [2],\n",
    "    \"fold_id\": fold_ids,\n",
    "    \"lambda_l1\": [0.3, 12, 40],\n",
    "    \"max_depth\": [10, 15, 17],\n",
    "    \"colsample_bytree\": [0.1, 0.3, 0.4],\n",
    "    \"alpha\": [0.2],\n",
    "    \"num_leaves\": [2048,],\n",
    "    \"learning_rate\": [0.03],\n",
    "    \"lambda_l2\": [0.01, 0.1],\n",
    "    \"max_bin\": [256,],\n",
    "    \"bagging_fraction\": [1],\n",
    "    \"deterministic\": [False],\n",
    "    \"objective\": [\"huber\"],\n",
    "    \"metric\": [\"huber\"],\n",
    "    \"n_estimators\": [20000],\n",
    "    \"random_state\": [42],\n",
    "    \"importance_type\": [\"gain\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_keys = list(param_grid.keys())\n",
    "param_values = list(param_grid.values())\n",
    "param_combinations = list(itertools.product(*param_values))\n",
    "\n",
    "# Create a list of dictionaries, each representing a specific combination\n",
    "param_dicts = []\n",
    "for combo in param_combinations:\n",
    "    param_dict = dict(zip(param_keys, combo))\n",
    "    param_dicts.append(param_dict)\n",
    "\n",
    "# Display the number of combinations and the first few combinations\n",
    "print(f\"Total number of parameter combinations: {len(param_dicts)}\")\n",
    "print(\"\\nFirst 3 parameter combinations:\")\n",
    "for i in range(min(3, len(param_dicts))):\n",
    "    print(f\"Combination {i+1}:\")\n",
    "    print(param_dicts[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c624c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>length of rdd_result: 10\n",
      "CPU times: user 12.4 ms, sys: 3.57 ms, total: 16 ms\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_these = param_dicts[:10]  # Limit to the first 10 combinations for testing\n",
    "\n",
    "rdd = sc.parallelize(process_these, numSlices=len(process_these))\n",
    "\n",
    "rdd_result = rdd.map(lambda x: train_lightgbm_model(params=x)).collect()\n",
    "\n",
    "print(f\">>>>length of rdd_result: {len(rdd_result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248fd044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    fold_id  accuracy  precision    recall  f1_score   auc_roc  training_time  \\\n",
       "0        1   0.85750   0.929913  0.701590  0.799775  0.940603      23.300903   \n",
       "1        1   0.86115   0.934811  0.707013  0.805109  0.942692      21.284032   \n",
       "2        1   0.92600   0.952517  0.860471  0.904157  0.967199      29.583189   \n",
       "3        1   0.92855   0.952478  0.867127  0.907801  0.967815      26.705687   \n",
       "4        1   0.93405   0.952571  0.881302  0.915552  0.967652      36.456858   \n",
       "5        1   0.93280   0.953747  0.876864  0.913691  0.967790      36.798010   \n",
       "6        1   0.84525   0.921822  0.675829  0.779888  0.933211      26.306204   \n",
       "7        1   0.84790   0.917917  0.686429  0.785472  0.932914      21.543370   \n",
       "8        1   0.91940   0.954171  0.841735  0.894434  0.966156      21.920865   \n",
       "9        1   0.91560   0.954449  0.831628  0.888816  0.966006      20.701826   \n",
       "\n",
       "   n_jobs  lambda_l1  max_depth  ...  learning_rate  lambda_l2  max_bin  \\\n",
       "0       2        0.3         10  ...           0.03       0.01      256   \n",
       "1       2        0.3         10  ...           0.03       0.10      256   \n",
       "2       2        0.3         10  ...           0.03       0.01      256   \n",
       "3       2        0.3         10  ...           0.03       0.10      256   \n",
       "4       2        0.3         10  ...           0.03       0.01      256   \n",
       "5       2        0.3         10  ...           0.03       0.10      256   \n",
       "6       2        0.3         15  ...           0.03       0.01      256   \n",
       "7       2        0.3         15  ...           0.03       0.10      256   \n",
       "8       2        0.3         15  ...           0.03       0.01      256   \n",
       "9       2        0.3         15  ...           0.03       0.10      256   \n",
       "\n",
       "   bagging_fraction  deterministic  objective  metric  n_estimators  \\\n",
       "0                 1          False      huber   huber         20000   \n",
       "1                 1          False      huber   huber         20000   \n",
       "2                 1          False      huber   huber         20000   \n",
       "3                 1          False      huber   huber         20000   \n",
       "4                 1          False      huber   huber         20000   \n",
       "5                 1          False      huber   huber         20000   \n",
       "6                 1          False      huber   huber         20000   \n",
       "7                 1          False      huber   huber         20000   \n",
       "8                 1          False      huber   huber         20000   \n",
       "9                 1          False      huber   huber         20000   \n",
       "\n",
       "  random_state importance_type  \n",
       "0           42            gain  \n",
       "1           42            gain  \n",
       "2           42            gain  \n",
       "3           42            gain  \n",
       "4           42            gain  \n",
       "5           42            gain  \n",
       "6           42            gain  \n",
       "7           42            gain  \n",
       "8           42            gain  \n",
       "9           42            gain  \n",
       "\n",
       "[10 rows x 23 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [pd.read_parquet(fp) for fp in rdd_result]\n",
    "results_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "results_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c97346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "training_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "auc_roc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4307009a-4a51-469f-9439-727a39e552dc",
       "rows": [
        [
         "count",
         "10.0",
         "10.0",
         "10.0",
         "10.0",
         "10.0",
         "10.0"
        ],
        [
         "mean",
         "26.46009445759996",
         "0.89682",
         "0.9424396653027636",
         "0.7929988906692962",
         "0.8594694486477709",
         "0.9552037894205109"
        ],
        [
         "std",
         "6.0677110062054425",
         "0.03840209195690604",
         "0.014743086275178108",
         "0.08792715276511337",
         "0.058527365437500124",
         "0.015645963960801933"
        ],
        [
         "min",
         "20.701825884000073",
         "0.84525",
         "0.9179165979891215",
         "0.6758289165536793",
         "0.7798876324585734",
         "0.9329142514626646"
        ],
        [
         "25%",
         "21.637744041249903",
         "0.8584125",
         "0.9311377975708053",
         "0.7029458893134476",
         "0.8011086722467863",
         "0.941125041218962"
        ],
        [
         "50%",
         "24.803553573499926",
         "0.9175",
         "0.9524975285410695",
         "0.8366818686059411",
         "0.8916246163014709",
         "0.9660806140189983"
        ],
        [
         "75%",
         "28.863813731499903",
         "0.9279125",
         "0.9534531823975507",
         "0.8654628374214224",
         "0.9068897505819006",
         "0.9675386902452593"
        ],
        [
         "max",
         "36.798010474999955",
         "0.93405",
         "0.9544490026877918",
         "0.8813016146924689",
         "0.9155515718035726",
         "0.9678153903985403"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.460094</td>\n",
       "      <td>0.896820</td>\n",
       "      <td>0.942440</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>0.859469</td>\n",
       "      <td>0.955204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.067711</td>\n",
       "      <td>0.038402</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.087927</td>\n",
       "      <td>0.058527</td>\n",
       "      <td>0.015646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.701826</td>\n",
       "      <td>0.845250</td>\n",
       "      <td>0.917917</td>\n",
       "      <td>0.675829</td>\n",
       "      <td>0.779888</td>\n",
       "      <td>0.932914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.637744</td>\n",
       "      <td>0.858413</td>\n",
       "      <td>0.931138</td>\n",
       "      <td>0.702946</td>\n",
       "      <td>0.801109</td>\n",
       "      <td>0.941125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.803554</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.952498</td>\n",
       "      <td>0.836682</td>\n",
       "      <td>0.891625</td>\n",
       "      <td>0.966081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.863814</td>\n",
       "      <td>0.927913</td>\n",
       "      <td>0.953453</td>\n",
       "      <td>0.865463</td>\n",
       "      <td>0.906890</td>\n",
       "      <td>0.967539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.798010</td>\n",
       "      <td>0.934050</td>\n",
       "      <td>0.954449</td>\n",
       "      <td>0.881302</td>\n",
       "      <td>0.915552</td>\n",
       "      <td>0.967815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       training_time   accuracy  precision     recall   f1_score    auc_roc\n",
       "count      10.000000  10.000000  10.000000  10.000000  10.000000  10.000000\n",
       "mean       26.460094   0.896820   0.942440   0.792999   0.859469   0.955204\n",
       "std         6.067711   0.038402   0.014743   0.087927   0.058527   0.015646\n",
       "min        20.701826   0.845250   0.917917   0.675829   0.779888   0.932914\n",
       "25%        21.637744   0.858413   0.931138   0.702946   0.801109   0.941125\n",
       "50%        24.803554   0.917500   0.952498   0.836682   0.891625   0.966081\n",
       "75%        28.863814   0.927913   0.953453   0.865463   0.906890   0.967539\n",
       "max        36.798010   0.934050   0.954449   0.881302   0.915552   0.967815"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[\"training_time\", \"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auc_roc\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3afb8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f8ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
