{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7cf9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n",
      "Spark UI available at: http://d06357a3e3b7:4040\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkDataScienceSample\") \\\n",
    "    .master(os.environ.get(\"SPARK_MASTER\", \"spark://spark-master:7077\")) \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8534dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature_3_cat",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "feature_5_cat",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "08103db8-5491-41f3-b016-84c944bfa80c",
       "rows": [
        [
         "0",
         "A1",
         "B5"
        ],
        [
         "1",
         "A3",
         "B4"
        ],
        [
         "2",
         "A2",
         "B3"
        ],
        [
         "3",
         "A2",
         "B5"
        ],
        [
         "4",
         "A2",
         "B1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_3_cat</th>\n",
       "      <th>feature_5_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3</td>\n",
       "      <td>B4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>B5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_3_cat feature_5_cat\n",
       "0            A1            B5\n",
       "1            A3            B4\n",
       "2            A2            B3\n",
       "3            A2            B5\n",
       "4            A2            B1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for each feature:\n",
      "\n",
      "feature_3_cat:\n",
      "feature_3_cat\n",
      "A3    336\n",
      "A1    334\n",
      "A2    330\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feature_5_cat:\n",
      "feature_5_cat\n",
      "B1    206\n",
      "B5    204\n",
      "B3    203\n",
      "B2    201\n",
      "B4    186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame with categorical features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Define categories for each feature\n",
    "cats1 = [f\"A{i}\" for i in range(1, 4)]   # 3 categories\n",
    "cats2 = [f\"B{i}\" for i in range(1, 6)]   # 5 categories\n",
    "cats3 = [f\"C{i}\" for i in range(1, 8)]   # 7 categories\n",
    "\n",
    "# Randomly choose categories for each row\n",
    "col1 = rng.choice(cats1, size=n)\n",
    "col2 = rng.choice(cats2, size=n)\n",
    "col3 = rng.choice(cats3, size=n)\n",
    "\n",
    "# Build DataFrame and set categorical dtype\n",
    "df = pd.DataFrame({\n",
    "    \"feature_3_cat\": pd.Categorical(col1, categories=cats1),\n",
    "    \"feature_5_cat\": pd.Categorical(col2, categories=cats2),\n",
    "    # \"feature_7_cat\": pd.Categorical(col3, categories=cats3),\n",
    "})\n",
    "\n",
    "# Show preview and category counts\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "print('\\nValue counts for each feature:')\n",
    "for c in df.columns:\n",
    "    print(f\"\\n{c}:\")\n",
    "    print(df[c].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95747e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2843/2582041475.py:3: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  cat_cols = [c for c in df.columns if pd.api.types.is_categorical_dtype(df[c])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark DataFrame schema:\n",
      "root\n",
      " |-- feature_3_cat: string (nullable = true)\n",
      " |-- feature_5_cat: string (nullable = true)\n",
      "\n",
      "\n",
      "Preview:\n",
      "+-------------+-------------+\n",
      "|feature_3_cat|feature_5_cat|\n",
      "+-------------+-------------+\n",
      "|A1           |B5           |\n",
      "|A3           |B4           |\n",
      "|A2           |B3           |\n",
      "|A2           |B5           |\n",
      "|A2           |B1           |\n",
      "|A3           |B5           |\n",
      "|A1           |B5           |\n",
      "|A3           |B3           |\n",
      "|A1           |B4           |\n",
      "|A1           |B3           |\n",
      "+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "+-------------+-------------+\n",
      "|feature_3_cat|feature_5_cat|\n",
      "+-------------+-------------+\n",
      "|A1           |B5           |\n",
      "|A3           |B4           |\n",
      "|A2           |B3           |\n",
      "|A2           |B5           |\n",
      "|A2           |B1           |\n",
      "|A3           |B5           |\n",
      "|A1           |B5           |\n",
      "|A3           |B3           |\n",
      "|A1           |B4           |\n",
      "|A1           |B3           |\n",
      "+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "Row count: 1000\n",
      "Row count: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[feature_3_cat: string, feature_5_cat: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pandas categorical columns to string before creating Spark DataFrame\n",
    "# This avoids Spark inferring pandas Categorical dtype incorrectly.\n",
    "cat_cols = [c for c in df.columns if pd.api.types.is_categorical_dtype(df[c])]\n",
    "if cat_cols:\n",
    "    df[cat_cols] = df[cat_cols].astype(str)\n",
    "\n",
    "# Create Spark DataFrame from pandas DataFrame\n",
    "# `spark` is expected to be defined in a previous cell (SparkSession)\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Show schema and first few rows\n",
    "print(\"Spark DataFrame schema:\")\n",
    "spark_df.printSchema()\n",
    "print(\"\\nPreview:\")\n",
    "spark_df.show(10, truncate=False)\n",
    "\n",
    "# Optional: cache and count to materialize\n",
    "spark_df = spark_df.cache()\n",
    "print(f\"Row count: {spark_df.count()}\")\n",
    "\n",
    "# Expose for downstream cells\n",
    "spark_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f373ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns detected: ['feature_3_cat', 'feature_5_cat']\n",
      "Schema after OHE pipeline:\n",
      "root\n",
      " |-- feature_3_cat: string (nullable = true)\n",
      " |-- feature_5_cat: string (nullable = true)\n",
      " |-- feature_3_cat_idx: double (nullable = false)\n",
      " |-- feature_5_cat_idx: double (nullable = false)\n",
      " |-- feature_3_cat_ohe: vector (nullable = true)\n",
      " |-- feature_5_cat_ohe: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "\n",
      "Preview of OHE features:\n",
      "Schema after OHE pipeline:\n",
      "root\n",
      " |-- feature_3_cat: string (nullable = true)\n",
      " |-- feature_5_cat: string (nullable = true)\n",
      " |-- feature_3_cat_idx: double (nullable = false)\n",
      " |-- feature_5_cat_idx: double (nullable = false)\n",
      " |-- feature_3_cat_ohe: vector (nullable = true)\n",
      " |-- feature_5_cat_ohe: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "\n",
      "Preview of OHE features:\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "|feature_3_cat|feature_5_cat|feature_3_cat_ohe|feature_5_cat_ohe|features           |\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "|A1           |B5           |(3,[1],[1.0])    |(5,[1],[1.0])    |(8,[1,4],[1.0,1.0])|\n",
      "|A3           |B4           |(3,[0],[1.0])    |(5,[4],[1.0])    |(8,[0,7],[1.0,1.0])|\n",
      "|A2           |B3           |(3,[2],[1.0])    |(5,[2],[1.0])    |(8,[2,5],[1.0,1.0])|\n",
      "|A2           |B5           |(3,[2],[1.0])    |(5,[1],[1.0])    |(8,[2,4],[1.0,1.0])|\n",
      "|A2           |B1           |(3,[2],[1.0])    |(5,[0],[1.0])    |(8,[2,3],[1.0,1.0])|\n",
      "|A3           |B5           |(3,[0],[1.0])    |(5,[1],[1.0])    |(8,[0,4],[1.0,1.0])|\n",
      "|A1           |B5           |(3,[1],[1.0])    |(5,[1],[1.0])    |(8,[1,4],[1.0,1.0])|\n",
      "|A3           |B3           |(3,[0],[1.0])    |(5,[2],[1.0])    |(8,[0,5],[1.0,1.0])|\n",
      "|A1           |B4           |(3,[1],[1.0])    |(5,[4],[1.0])    |(8,[1,7],[1.0,1.0])|\n",
      "|A1           |B3           |(3,[1],[1.0])    |(5,[2],[1.0])    |(8,[1,5],[1.0,1.0])|\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "|feature_3_cat|feature_5_cat|feature_3_cat_ohe|feature_5_cat_ohe|features           |\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "|A1           |B5           |(3,[1],[1.0])    |(5,[1],[1.0])    |(8,[1,4],[1.0,1.0])|\n",
      "|A3           |B4           |(3,[0],[1.0])    |(5,[4],[1.0])    |(8,[0,7],[1.0,1.0])|\n",
      "|A2           |B3           |(3,[2],[1.0])    |(5,[2],[1.0])    |(8,[2,5],[1.0,1.0])|\n",
      "|A2           |B5           |(3,[2],[1.0])    |(5,[1],[1.0])    |(8,[2,4],[1.0,1.0])|\n",
      "|A2           |B1           |(3,[2],[1.0])    |(5,[0],[1.0])    |(8,[2,3],[1.0,1.0])|\n",
      "|A3           |B5           |(3,[0],[1.0])    |(5,[1],[1.0])    |(8,[0,4],[1.0,1.0])|\n",
      "|A1           |B5           |(3,[1],[1.0])    |(5,[1],[1.0])    |(8,[1,4],[1.0,1.0])|\n",
      "|A3           |B3           |(3,[0],[1.0])    |(5,[2],[1.0])    |(8,[0,5],[1.0,1.0])|\n",
      "|A1           |B4           |(3,[1],[1.0])    |(5,[4],[1.0])    |(8,[1,7],[1.0,1.0])|\n",
      "|A1           |B3           |(3,[1],[1.0])    |(5,[2],[1.0])    |(8,[1,5],[1.0,1.0])|\n",
      "+-------------+-------------+-----------------+-----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "Row count after transform: 1000\n",
      "Row count after transform: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[feature_3_cat: string, feature_5_cat: string, feature_3_cat_idx: double, feature_5_cat_idx: double, feature_3_cat_ohe: vector, feature_5_cat_ohe: vector, features: vector]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode categorical features using Spark ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "# Identify categorical columns in spark_df (we converted them to strings earlier)\n",
    "cat_cols = [c for c, t in spark_df.dtypes if t == 'string']\n",
    "print('Categorical columns detected:', cat_cols)\n",
    "\n",
    "# Create indexers and encoders\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid='keep') for c in cat_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{c}_idx\", outputCol=f\"{c}_ohe\") for c in cat_cols]\n",
    "\n",
    "# Assemble all OHE vectors into a single feature vector\n",
    "ohe_cols = [f\"{c}_ohe\" for c in cat_cols]\n",
    "assembler = VectorAssembler(inputCols=ohe_cols, outputCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "model = pipeline.fit(spark_df)\n",
    "\n",
    "spark_df_ohe = model.transform(spark_df)\n",
    "\n",
    "print('Schema after OHE pipeline:')\n",
    "spark_df_ohe.printSchema()\n",
    "print('\\nPreview of OHE features:')\n",
    "spark_df_ohe.select(*cat_cols, *ohe_cols, 'features').show(10, truncate=False)\n",
    "\n",
    "# Cache and count to materialize\n",
    "spark_df_ohe = spark_df_ohe.cache()\n",
    "print(f\"Row count after transform: {spark_df_ohe.count()}\")\n",
    "\n",
    "# Expose for downstream cells\n",
    "spark_df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a58ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyspark.ml.functions.vector_to_array (native)\n",
      "Converted to pandas DataFrame with shape: (1000, 10)\n",
      "Converted to pandas DataFrame with shape: (1000, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature_3_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "feature_5_cat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "f_0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f_7",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3276c63e-2136-4e8a-9111-40f2b71644c9",
       "rows": [
        [
         "0",
         "A1",
         "B5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "A3",
         "B4",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "2",
         "A2",
         "B3",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "A2",
         "B5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "A1",
         "B5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "A3",
         "B3",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "A1",
         "B4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "9",
         "A1",
         "B3",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "11",
         "A3",
         "B4",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "12",
         "A3",
         "B2",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "13",
         "A3",
         "B2",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "14",
         "A3",
         "B3",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "17",
         "A1",
         "B3",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "18",
         "A3",
         "B1",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "20",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "A1",
         "B5",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "26",
         "A2",
         "B1",
         "0.0",
         "0.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "27",
         "A3",
         "B2",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "28",
         "A2",
         "B3",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "29",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "30",
         "A2",
         "B3",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         "A1",
         "B1",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         "A1",
         "B4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "33",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "34",
         "A3",
         "B1",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "35",
         "A1",
         "B4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "36",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "A3",
         "B1",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         "A1",
         "B3",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "A2",
         "B5",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "A1",
         "B4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "41",
         "A3",
         "B5",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "42",
         "A3",
         "B3",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "43",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "44",
         "A1",
         "B4",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "45",
         "A3",
         "B1",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "A2",
         "B2",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "47",
         "A3",
         "B4",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "48",
         "A3",
         "B4",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "49",
         "A3",
         "B1",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 1000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_3_cat</th>\n",
       "      <th>feature_5_cat</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>B5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3</td>\n",
       "      <td>B4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>B5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A2</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>A2</td>\n",
       "      <td>B3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A2</td>\n",
       "      <td>B5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>A3</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_3_cat feature_5_cat  f_0  f_1  f_2  f_3  f_4  f_5  f_6  f_7\n",
       "0              A1            B5  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "1              A3            B4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "2              A2            B3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0\n",
       "3              A2            B5  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0\n",
       "4              A2            B1  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       "..            ...           ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "995            A2            B1  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0\n",
       "996            A2            B3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0\n",
       "997            A2            B5  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0\n",
       "998            A3            B2  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "999            A2            B2  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0\n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the Spark DataFrame with OHE features back to pandas\n",
    "# WARNING: toPandas() collects data to the driver. Make sure the dataset fits in driver memory.\n",
    "\n",
    "# Prefer Spark-native conversion if available (avoids Python pickling issues)\n",
    "try:\n",
    "    from pyspark.ml.functions import vector_to_array\n",
    "    use_native = True\n",
    "except Exception:\n",
    "    use_native = False\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "if use_native:\n",
    "    print('Using pyspark.ml.functions.vector_to_array (native)')\n",
    "    df_for_pandas = spark_df_ohe.select(*(c for c in spark_df_ohe.columns if not c.endswith('_idx') and not c.endswith('_ohe')), 'features')\n",
    "    df_for_pandas = df_for_pandas.withColumn('features_array', vector_to_array('features'))\n",
    "    pandas_df = df_for_pandas.drop('features').toPandas()\n",
    "else:\n",
    "    print('vector_to_array not available — falling back to safe UDF')\n",
    "    from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "    def vector_to_pylist(v):\n",
    "        if v is None:\n",
    "            return None\n",
    "        arr = v.toArray()\n",
    "        return [float(x) for x in arr]\n",
    "\n",
    "    vector_to_pylist_udf = udf(vector_to_pylist, ArrayType(DoubleType()))\n",
    "    df_for_pandas = spark_df_ohe.select(*(c for c in spark_df_ohe.columns if not c.endswith('_idx') and not c.endswith('_ohe')), 'features')\n",
    "    df_for_pandas = df_for_pandas.withColumn('features_array', vector_to_pylist_udf('features'))\n",
    "    pandas_df = df_for_pandas.drop('features').toPandas()\n",
    "\n",
    "# Expand features_array into separate DataFrame columns if desired\n",
    "if 'features_array' in pandas_df.columns:\n",
    "    features_df = pd.DataFrame(pandas_df['features_array'].tolist(), index=pandas_df.index).add_prefix('f_')\n",
    "    pandas_df = pd.concat([pandas_df.drop(columns=['features_array']), features_df], axis=1)\n",
    "\n",
    "print(f\"Converted to pandas DataFrame with shape: {pandas_df.shape}\")\n",
    "\n",
    "# Expose for downstream use\n",
    "pandas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fbea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
