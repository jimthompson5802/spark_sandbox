version: '3.8'

services:
  dev:
    build:
      context: .
      dockerfile: Dockerfile
    platform: linux/amd64
    container_name: jupyterlab-notebook
    volumes:
      - ./:/app
    ports:
      # Add ports as needed for your applications
      - "3000:3000"
      - "8888:8888"  # JupyterLab port
    environment:
      - TZ=UTC
    # Keep the container running
    tty: true
    stdin_open: true
    # Restart policy
    restart: unless-stopped

  spark-master:
    build:
      context: .
      dockerfile: Dockerfile_spark
    platform: linux/amd64
    container_name: spark-master
    environment:
      - SPARK_NODE_TYPE=master
      - SPARK_MASTER_HOST=spark-master
      - TZ=UTC
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master port
      - "4040:4040"  # Spark Application UI for running jobs
    volumes:
      - ./:/app
    networks:
      - spark-network
    restart: unless-stopped

  spark-worker-1:
    build:
      context: .
      dockerfile: Dockerfile_spark
    platform: linux/amd64
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_NODE_TYPE=worker
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - TZ=UTC
    ports:
      - "8081:8081"  # Worker UI
    volumes:
      - ./:/app
    networks:
      - spark-network
    restart: unless-stopped

  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile_spark
    platform: linux/amd64
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_NODE_TYPE=worker
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - TZ=UTC
    ports:
      - "8082:8081"  # Worker UI (different host port to avoid conflict)
    volumes:
      - ./:/app
    networks:
      - spark-network
    restart: unless-stopped

networks:
  spark-network:
    driver: bridge