FROM --platform=linux/amd64 openjdk:11-jdk-slim

# Set environment variables
ENV SPARK_VERSION=3.4.1
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark

# Install necessary packages
RUN apt-get update && \
    apt-get install -y wget curl bash tini procps && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Download and extract Apache Spark
RUN wget -q "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" -O /tmp/spark.tgz && \
    tar -xf /tmp/spark.tgz -C /opt && \
    ln -s /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} ${SPARK_HOME} && \
    rm /tmp/spark.tgz

# Set working directory
WORKDIR ${SPARK_HOME}

# Add Spark to PATH
ENV PATH=${SPARK_HOME}/bin:${PATH}

# Copy the entrypoint script
COPY docker/entrypoint.sh /
RUN chmod +x /entrypoint.sh

# Expose necessary ports
# Spark UI
EXPOSE 8080
# Spark Master port
EXPOSE 7077
# Spark Master UI
EXPOSE 8090
# Spark Worker UI
EXPOSE 8081
# Spark Driver Web UI
EXPOSE 4040

ENTRYPOINT ["/entrypoint.sh"]